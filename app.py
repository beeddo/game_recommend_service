import os
import torch
from transformers import AutoTokenizer, AutoModel
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import logging
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
from functools import lru_cache
import hashlib

app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('game_qa_data.csv')

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (ì„ë² ë”©ìš©)
model_name = 'klue/bert-base'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
model.eval()

# ì„ë² ë”© ìºì‹œë¥¼ ìœ„í•œ í•´ì‹œ í•¨ìˆ˜
def get_text_hash(text):
    return hashlib.md5(text.encode()).hexdigest()

# ìºì‹œëœ ì„ë² ë”© ì €ì¥ì†Œ
embedding_cache = {}

def get_embedding_cached(text):
    """ìºì‹œë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ê³„ì‚°"""
    text_hash = get_text_hash(text)
    
    if text_hash in embedding_cache:
        return embedding_cache[text_hash]
    
    # ìºì‹œì— ì—†ìœ¼ë©´ ìƒˆë¡œ ê³„ì‚°
    embedding = get_embedding(text)
    
    # ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 1000ê°œ)
    if len(embedding_cache) > 1000:
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
        oldest_key = next(iter(embedding_cache))
        del embedding_cache[oldest_key]
    
    embedding_cache[text_hash] = embedding
    return embedding

def get_embedding(text):
    """í…ìŠ¤íŠ¸ì˜ BERT ì„ë² ë”©ì„ êµ¬í•©ë‹ˆë‹¤."""
    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    with torch.no_grad():
        outputs = model(**inputs)
        # [CLS] í† í°ì˜ ì„ë² ë”©ì„ ì‚¬ìš©
        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()
    return embedding

def get_embedding_batch(texts, batch_size=32):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”©ì„ ê³„ì‚°í•©ë‹ˆë‹¤ (ì„±ëŠ¥ ìµœì í™”)"""
    embeddings = []
    
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        
        # ë°°ì¹˜ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(batch_texts, return_tensors='pt', max_length=512, 
                          truncation=True, padding=True)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model(**inputs)
            # [CLS] í† í°ì˜ ì„ë² ë”©ì„ ì‚¬ìš©
            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            embeddings.extend(batch_embeddings)
    
    return np.array(embeddings)

def extract_keywords(text):
    """ì§ˆë¬¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    text_lower = text.lower()
    
    # ë©€í‹°í”Œë ˆì´ì–´ ê´€ë ¨ í‚¤ì›Œë“œ
    multiplayer_keywords = ['ë©€í‹°', 'ì¹œêµ¬', 'í•¨ê»˜', 'í˜‘ë™', 'ê°™ì´', 'íŒ€', 'ë‘˜ì´', 'ì—¬ëŸ¿', 'ë‹¤ê°™ì´', 'í˜‘ë ¥']
    
    # ì¥ë¥´ ê´€ë ¨ í‚¤ì›Œë“œ
    genre_keywords = {
        'horror': ['ê³µí¬', 'í˜¸ëŸ¬', 'ë¬´ì„œìš´', 'ìŠ¤ë¦´', 'ê¸´ì¥'],
        'survival': ['ìƒì¡´', 'ì„œë°”ì´ë²Œ', 'ì‚´ì•„ë‚¨', 'ê·¹í•œ'],
        'action': ['ì•¡ì…˜', 'ì „íˆ¬', 'ì‹¸ì›€', 'ê²©íˆ¬'],
        'rpg': ['rpg', 'ë¡¤í”Œë ˆì‰', 'ìºë¦­í„°', 'ë ˆë²¨ì—…', 'ìŠ¤í‚¬'],
        'strategy': ['ì „ëµ', 'ì „ìˆ ', 'ê³„íš', 'ì§€íœ˜'],
        'puzzle': ['í¼ì¦', 'ìˆ˜ìˆ˜ê»˜ë¼', 'ë¬¸ì œ', 'ë…¼ë¦¬'],
        'simulation': ['ì‹œë®¬ë ˆì´ì…˜', 'ì‹œë®¬', 'ê²½ì˜', 'ê±´ì„¤', 'ë†ì¥'],
        'adventure': ['ì–´ë“œë²¤ì²˜', 'ëª¨í—˜', 'íƒí—˜', 'ì—¬í–‰'],
        'racing': ['ë ˆì´ì‹±', 'ê²½ì£¼', 'ë“œë¼ì´ë¹™', 'ìë™ì°¨'],
        'sports': ['ìŠ¤í¬ì¸ ', 'ì¶•êµ¬', 'ë†êµ¬', 'ì•¼êµ¬', 'ìš´ë™']
    }
    
    # í”Œë«í¼ ê´€ë ¨ í‚¤ì›Œë“œ
    platform_keywords = {
        'pc': ['pc', 'ì»´í“¨í„°', 'ìœˆë„ìš°'],
        'console': ['ps', 'xbox', 'switch', 'ì½˜ì†”', 'í”ŒìŠ¤', 'ì—‘ë°•'],
        'mobile': ['ëª¨ë°”ì¼', 'í•¸ë“œí°', 'ìŠ¤ë§ˆíŠ¸í°', 'ì•ˆë“œë¡œì´ë“œ', 'ios']
    }
    
    # ë‚œì´ë„ ê´€ë ¨ í‚¤ì›Œë“œ
    difficulty_keywords = {
        'easy': ['ì‰¬ìš´', 'ê°„ë‹¨í•œ', 'ì´ˆë³´', 'ìºì£¼ì–¼'],
        'hard': ['ì–´ë ¤ìš´', 'í•˜ë“œì½”ì–´', 'ë„ì „ì ì¸', 'ê·¹í•œ', 'ê³ ìˆ˜']
    }
    
    # í”Œë ˆì´ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ
    playstyle_keywords = {
        'solo': ['í˜¼ì', 'ì†”ë¡œ', 'ì‹±ê¸€', 'ê°œì¸'],
        'competitive': ['ê²½ìŸ', 'ëŒ€ì „', 'pvp', 'ë­í‚¹'],
        'casual': ['ìºì£¼ì–¼', 'í¸ì•ˆí•œ', 'íë§', 'ì—¬ìœ '],
        'hardcore': ['í•˜ë“œì½”ì–´', 'ì§„ì§€í•œ', 'ëª°ì…']
    }
    
    found_keywords = {
        'multiplayer': [kw for kw in multiplayer_keywords if kw in text_lower],
        'genre': {},
        'platform': {},
        'difficulty': {},
        'playstyle': {}
    }
    
    # ì¥ë¥´ í‚¤ì›Œë“œ ê²€ì‚¬
    for genre, keywords in genre_keywords.items():
        found = [kw for kw in keywords if kw in text_lower]
        if found:
            found_keywords['genre'][genre] = found
    
    # í”Œë«í¼ í‚¤ì›Œë“œ ê²€ì‚¬
    for platform, keywords in platform_keywords.items():
        found = [kw for kw in keywords if kw in text_lower]
        if found:
            found_keywords['platform'][platform] = found
    
    # ë‚œì´ë„ í‚¤ì›Œë“œ ê²€ì‚¬
    for diff, keywords in difficulty_keywords.items():
        found = [kw for kw in keywords if kw in text_lower]
        if found:
            found_keywords['difficulty'][diff] = found
    
    # í”Œë ˆì´ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ ê²€ì‚¬
    for style, keywords in playstyle_keywords.items():
        found = [kw for kw in keywords if kw in text_lower]
        if found:
            found_keywords['playstyle'][style] = found
    
    return found_keywords

def filter_candidates_by_keywords(user_question, df):
    """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í›„ë³´ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
    user_keywords = extract_keywords(user_question)
    original_size = len(df)
    filtered_df = df.copy()
    
    # 1. ë©€í‹°í”Œë ˆì´ì–´ vs ì†”ë¡œ í”Œë ˆì´ í•„í„°ë§ (ìƒí˜¸ ë°°íƒ€ì )
    if user_keywords['multiplayer']:
        print(f"ë©€í‹°í”Œë ˆì´ì–´ í‚¤ì›Œë“œ ê°ì§€: {user_keywords['multiplayer']}")
        multiplayer_mask = df['question'].str.contains('|'.join(['ë©€í‹°', 'ì¹œêµ¬', 'í•¨ê»˜', 'í˜‘ë™', 'ê°™ì´', 'íŒ€', 'ë‘˜ì´']), na=False)
        multiplayer_answer_mask = df['answer'].str.contains('|'.join(['ë©€í‹°', 'í˜‘ë™', 'íŒ€', 'ì¹œêµ¬', 'í•¨ê»˜', 'í˜‘ë ¥', 'co-op', 'Co-op']), na=False)
        negative_mask = ~df['answer'].str.contains('|'.join(['í˜¼ì', 'ì†”ë¡œ', 'ì‹±ê¸€', 'ê°œì¸', 'single']), na=False)
        filtered_df = df[(multiplayer_mask | multiplayer_answer_mask) & negative_mask]
        print(f"ë©€í‹°í”Œë ˆì´ì–´ í•„í„°ë§: {original_size} -> {len(filtered_df)}ê°œ")
    
    elif user_keywords['playstyle'].get('solo'):
        print(f"ì†”ë¡œ í”Œë ˆì´ í‚¤ì›Œë“œ ê°ì§€: {user_keywords['playstyle']['solo']}")
        solo_mask = df['question'].str.contains('|'.join(['í˜¼ì', 'ì†”ë¡œ', 'ì‹±ê¸€']), na=False)
        solo_answer_mask = df['answer'].str.contains('|'.join(['ì‹±ê¸€', 'í˜¼ì', 'ê°œì¸']), na=False)
        # ë©€í‹°í”Œë ˆì´ì–´ ê²Œì„ ì œì™¸
        negative_mask = ~df['answer'].str.contains('|'.join(['ë©€í‹°', 'í˜‘ë™', 'íŒ€', 'co-op']), na=False)
        filtered_df = df[(solo_mask | solo_answer_mask) | negative_mask]
        print(f"ì†”ë¡œ í”Œë ˆì´ í•„í„°ë§: {original_size} -> {len(filtered_df)}ê°œ")
    
    # 2. ì¥ë¥´ í•„í„°ë§ (ê¸°ì¡´ í•„í„°ë§ëœ ê²°ê³¼ì— ì¶”ê°€ ì ìš©)
    if user_keywords['genre']:
        for genre, keywords in user_keywords['genre'].items():
            print(f"{genre} ì¥ë¥´ í‚¤ì›Œë“œ ê°ì§€: {keywords}")
            
            # ì¥ë¥´ë³„ ë§ˆìŠ¤í¬ ìƒì„±
            if genre == 'horror':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['ê³µí¬', 'í˜¸ëŸ¬', 'horror', 'Horror']), na=False, case=False)
            elif genre == 'survival':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['ìƒì¡´', 'ì„œë°”ì´ë²Œ', 'survival', 'Survival']), na=False, case=False)
            elif genre == 'action':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['ì•¡ì…˜', 'action', 'Action', 'ì „íˆ¬']), na=False, case=False)
            elif genre == 'rpg':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['RPG', 'rpg', 'ë¡¤í”Œë ˆì‰']), na=False, case=False)
            elif genre == 'strategy':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['ì „ëµ', 'strategy', 'Strategy', 'ì „ìˆ ']), na=False, case=False)
            elif genre == 'simulation':
                genre_mask = filtered_df['answer'].str.contains('|'.join(['ì‹œë®¬ë ˆì´ì…˜', 'simulation', 'Simulation']), na=False, case=False)
            else:
                continue
            
            # í•„í„°ë§ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì ìš©í•˜ì§€ ì•ŠìŒ (ìµœì†Œ 30ê°œ ìœ ì§€)
            potential_filtered = filtered_df[genre_mask]
            if len(potential_filtered) >= 30:
                filtered_df = potential_filtered
                print(f"{genre} ì¥ë¥´ í•„í„°ë§ ì ìš©: {len(filtered_df)}ê°œ")
            else:
                print(f"{genre} ì¥ë¥´ í•„í„°ë§ ìŠ¤í‚µ: í›„ë³´ê°€ ë„ˆë¬´ ì ìŒ ({len(potential_filtered)}ê°œ)")
    
    # 3. ë‚œì´ë„ í•„í„°ë§ (ì„ íƒì )
    if user_keywords['difficulty']:
        for diff, keywords in user_keywords['difficulty'].items():
            print(f"{diff} ë‚œì´ë„ í‚¤ì›Œë“œ ê°ì§€: {keywords}")
            if diff == 'hard':
                # í•˜ë“œì½”ì–´ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²Œì„ ìš°ì„ 
                hard_mask = filtered_df['answer'].str.contains('|'.join(['í•˜ë“œì½”ì–´', 'hardcore', 'ë„ì „ì ', 'ì–´ë ¤ìš´']), na=False, case=False)
                potential_filtered = filtered_df[hard_mask]
                if len(potential_filtered) >= 20:
                    filtered_df = potential_filtered
                    print(f"í•˜ë“œì½”ì–´ ë‚œì´ë„ í•„í„°ë§ ì ìš©: {len(filtered_df)}ê°œ")
    
    print(f"ìµœì¢… í•„í„°ë§ ê²°ê³¼: {original_size} -> {len(filtered_df)}ê°œ í›„ë³´ ({(1-len(filtered_df)/original_size)*100:.1f}% ê°ì†Œ)")
    return filtered_df

# ë¯¸ë¦¬ ì§ˆë¬¸ë“¤ì˜ ì„ë² ë”©ì„ ê³„ì‚° (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”)
print("ì§ˆë¬¸ ì„ë² ë”©ì„ ê³„ì‚° ì¤‘...")
questions = df['question'].tolist()

# ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ê³„ì‚°
batch_size = 16  # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
question_embeddings = []

for i in range(0, len(questions), batch_size):
    batch_questions = questions[i:i+batch_size]
    batch_embeddings = get_embedding_batch(batch_questions, batch_size=len(batch_questions))
    question_embeddings.extend(batch_embeddings)
    
    if i % (batch_size * 10) == 0:
        print(f"ì§„í–‰ë¥ : {i}/{len(questions)} ({i/len(questions)*100:.1f}%)")

question_embeddings = np.array(question_embeddings)
print("ì„ë² ë”© ê³„ì‚° ì™„ë£Œ!")

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        question = data.get('question', '')
        
        if not question:
            return jsonify({'error': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
        filtered_df = filter_candidates_by_keywords(question, df)
        
        # í•„í„°ë§ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©
        if len(filtered_df) < len(df):
            filtered_indices = filtered_df.index.tolist()
            filtered_embeddings = question_embeddings[filtered_indices]
        else:
            filtered_indices = list(range(len(df)))
            filtered_embeddings = question_embeddings
        
        # ì…ë ¥ ì§ˆë¬¸ì˜ ì„ë² ë”© ê³„ì‚°
        user_embedding = get_embedding_cached(question)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(user_embedding, filtered_embeddings)[0]
        
        # ìƒìœ„ 3ê°œ ìœ ì‚¬í•œ ì§ˆë¬¸ ì°¾ê¸°
        top_local_indices = np.argsort(similarities)[::-1][:3]
        best_local_idx = top_local_indices[0]
        best_global_idx = filtered_indices[best_local_idx]
        best_similarity = similarities[best_local_idx]
        
        # ë””ë²„ê¹… ì •ë³´ - ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
        print(f"ì‚¬ìš©ì ì§ˆë¬¸: {question}")
        print(f"í•„í„°ë§ëœ í›„ë³´ ìˆ˜: {len(filtered_df)}")
        print("ìƒìœ„ 3ê°œ ë§¤ì¹­ ê²°ê³¼:")
        for i, local_idx in enumerate(top_local_indices):
            global_idx = filtered_indices[local_idx]
            sim = similarities[local_idx]
            matched_q = df.iloc[global_idx]['question']
            print(f"  {i+1}. ìœ ì‚¬ë„: {sim:.3f} - {matched_q}")
        
        # ë” ì—„ê²©í•œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
        threshold = 0.6  # 0.5ì—ì„œ 0.6ìœ¼ë¡œ ìƒí–¥
        if best_similarity < threshold:
            answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ê²Œì„ ì¶”ì²œì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„: {best_similarity:.3f}) ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì‹œê² ì–´ìš”?"
        else:
            answer = df.iloc[best_global_idx]['answer']
        
        return jsonify({
            'question': question,
            'answer': answer,
            'similarity': float(best_similarity),
            'matched_question': df.iloc[best_global_idx]['question'],
            'filtered_candidates': len(filtered_df)
        })
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    logger.info("ğŸ® PickGame - AI ê²Œì„ ì¶”ì²œ ì›¹ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (í›ˆë ¨ëœ ëª¨ë¸ í•„ìš”)...")
    app.run(host='0.0.0.0', debug=True)

